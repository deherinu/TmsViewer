{
 "metadata": {
  "name": "",
  "signature": "sha256:cfb6a5b5c8d2f63111ec7af4ac279c74532434d6323d2d56bf97475389ec3020"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "TMS - optitracking calibration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This file demonstrates how to convert the data taken during the calibration procedure into useful values that can be used for visualizing and analysing the data. This process should be carried out interactively in a python console or notebook, as in this example. We will start by loading some modules we will use throughout the process"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import scipy.optimize\n",
      "import sys\n",
      "import os\n",
      "import datetime\n",
      "from itertools import izip\n",
      "#change this to the directory containing your tms-data\n",
      "os.chdir(r\"C:\\Users\\da.angulo39\\Dropbox\\VaBD\\ProyectoSavingBrains\\TMS-Optitracking\\TMS_Data Agosto 2014\")\n",
      "#directory containing the tms view 2 project\n",
      "sys.path.append(r\"C:\\Users\\da.angulo39\\Dropbox\\VaBD\\ProyectoSavingBrains\\TMS-Optitracking\\tms_view2\")\n",
      "from tms import quat\n",
      "#utility functions used during the calibration\n",
      "from tms.calibration_commands import *\n",
      "from tms  import tms_utils as tms\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2 Coil Calibration\n",
      "\n",
      "Here the objective is to obtain a function that will transform the vrpn values into coordinates corresponding to the center of the coil, and to an hypotethical point located 10 units over the center. This will be useful for drawing the cones that indicate the direction of the stimulation.\n",
      "\n",
      "### 2.0 Prerequisites\n",
      "\n",
      "The pointer calibration should have been completed, and the $v$ values saved into the calibration_data.py file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "calib_date = datetime.date(2014, 7, 31)\n",
      "point_f = get_pointer_point_function(calib_date)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.1 Loading the data\n",
      "\n",
      "The first step is loading the samples for this calibration. This should be loaded into a list. In order to keep data organized, this information should be saved in the calibration_data.py file. We will use a function from calibration commands"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coil_samples = load_coil_samples(calib_date)\n",
      "print coil_samples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['72000', '74000', '75000', '76000', '77000', '78000']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are going to load the data inside this files, "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coil_data = map(load_data,coil_samples)\n",
      "for d in coil_data[2]:\n",
      "    print d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Point with reference:\n",
        "=====================\n",
        "Type: 1\n",
        "Capture Time : Thu Jul 31 17:51:43 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:33:44 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.14 , -0.11 , -0.78\n",
        "object  orn  : 0.24 , 0.92 , 0.28 , 0.12\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 2\n",
        "Capture Time : Thu Jul 31 17:51:53 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:33:54 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.16 , -0.13 , -0.38\n",
        "object  orn  : 0.71 , -0.58 , -0.22 , -0.35\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 3\n",
        "Capture Time : Thu Jul 31 17:52:03 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:34:04 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.29 , -0.11 , -0.67\n",
        "object  orn  : 0.33 , 0.80 , 0.08 , 0.49\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 4\n",
        "Capture Time : Thu Jul 31 17:52:13 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:34:14 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.05 , -0.13 , -0.59\n",
        "object  orn  : -0.10 , -0.89 , -0.35 , 0.28\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 0\n",
        "Capture Time : Thu Jul 31 17:52:27 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:34:27 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.18 , -0.18 , -0.54\n",
        "object  orn  : 0.59 , 0.23 , 0.77 , 0.02\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 0\n",
        "Capture Time : Thu Jul 31 17:52:31 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:34:32 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.18 , -0.18 , -0.54\n",
        "object  orn  : 0.59 , 0.23 , 0.77 , 0.02\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 0\n",
        "Capture Time : Thu Jul 31 17:52:36 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:34:37 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.18 , -0.18 , -0.54\n",
        "object  orn  : 0.59 , 0.23 , 0.77 , 0.02\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 0\n",
        "Capture Time : Thu Jul 31 17:52:41 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:34:41 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.18 , -0.18 , -0.54\n",
        "object  orn  : 0.59 , 0.23 , 0.77 , 0.02\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is lots of information in these files, because we are only calibrating the sample we don't care about the reference. There should be four calibration samples, and about 4 Coil samples for each index. \n",
      "\n",
      "Now we should look at each of the samples separately in order to find obvious problems. If any of them looks problematic (for example, contains missing values) we should remove it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(coil_data)\n",
      "#save a copy, handy\n",
      "orig_coil_data = coil_data[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Be sure to look at all the samples by changing the index in the next command... Afterwards do any cleanup necessary in the next cell."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for d in orig_coil_data[5]:\n",
      "    print d\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Point with reference:\n",
        "=====================\n",
        "Type: 1\n",
        "Capture Time : Thu Jul 31 17:57:37 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:39:38 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.13 , -0.11 , -0.95\n",
        "object  orn  : 0.23 , 0.91 , 0.25 , -0.25\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 2\n",
        "Capture Time : Thu Jul 31 17:57:48 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:39:48 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.37 , -0.11 , -0.61\n",
        "object  orn  : 0.07 , -0.14 , -0.31 , 0.94\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 3\n",
        "Capture Time : Thu Jul 31 17:57:58 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:39:58 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.19 , -0.11 , -0.83\n",
        "object  orn  : -0.15 , -0.82 , -0.44 , 0.34\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 4\n",
        "Capture Time : Thu Jul 31 17:58:08 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:40:08 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.14 , -0.14 , -0.76\n",
        "object  orn  : -0.16 , -0.76 , -0.38 , 0.51\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 0\n",
        "Capture Time : Thu Jul 31 17:58:21 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:40:21 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.29 , -0.18 , -0.76\n",
        "object  orn  : 0.29 , 0.12 , 0.95 , 0.00\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 0\n",
        "Capture Time : Thu Jul 31 17:58:27 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:40:27 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.29 , -0.18 , -0.76\n",
        "object  orn  : 0.28 , 0.12 , 0.95 , 0.01\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 0\n",
        "Capture Time : Thu Jul 31 17:58:31 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:40:32 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.29 , -0.18 , -0.76\n",
        "object  orn  : 0.28 , 0.12 , 0.95 , 0.00\n",
        "\n",
        "Point with reference:\n",
        "=====================\n",
        "Type: 0\n",
        "Capture Time : Thu Jul 31 17:58:36 COT 2014\n",
        "Refer.  Time : Wed Dec 31 19:26:46 COT 1969\n",
        "Object  Time : Wed Dec 31 19:40:37 COT 1969\n",
        "Ref.    pos  : 0.45 , 0.19 , -0.09\n",
        "Ref.    orn  : -0.54 , 0.32 , -0.24 , -0.74\n",
        "object  pos  : 0.29 , -0.18 , -0.76\n",
        "object  orn  : 0.28 , 0.12 , 0.95 , 0.00\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coil_data = [orig_coil_data[i] for i in (0,3,5)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are going to split the samples in two groups, stage_one are the ones where the pointer is placed at specific points over the coil and stage two will be the ones where the tms is fired and the information from the coil tracker is captured"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stage_one = [filter(lambda x:x.type!=0,s) for s in coil_data]\n",
      "stage_two = [filter(lambda x:x.type==0,s) for s in coil_data]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, lets keep only the position and orientation, and transform the orientation to quaternions objects. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stage_one_pairs = [map(transform_sample_no_ref,s) for s in stage_one]\n",
      "stage_two_pairs = [map(transform_sample_no_ref,s) for s in stage_two]\n",
      "print stage_one_pairs[0][1]\n",
      "print stage_two_pairs[0][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PointerSample(pos=array([-0.15547048, -0.12189659, -0.30221459]), orn=Quaternion:\n",
        "array([ 0.13251033,  0.90811127,  0.25194061, -0.30708441]))\n",
        "PointerSample(pos=array([-0.00045285, -0.18386754, -0.325394  ]), orn=Quaternion:\n",
        "array([ 0.92539769,  0.21715081,  0.27713248,  0.14029373]))\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now use the pointer_point function to get the positions of the points from the samples in stage one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stage_one_points = [map(lambda x:point_f(x.pos,x.orn),s) for s in stage_one_pairs]\n",
      "# create a dictionaries to match the image shown below\n",
      "stage_one_dicts = [dict((izip((1,2,3,4),pts))) for pts in stage_one_points]\n",
      "len(stage_one_dicts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets take a look at this data using vtk. Look for the vtk window that will open after excecuting this cell.\n",
      "\n",
      "<img src=\"files/tmsCali.png\">"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# first let't get some colors\n",
      "import colorbrewer\n",
      "colors = colorbrewer.Set3[max(3,len(coil_data))]\n",
      "colors = map(lambda c:map(lambda x:x/255,c),colors)\n",
      "viewer = VtkViewer()\n",
      "for i,points_dict in enumerate(stage_one_dicts):\n",
      "    c = colors[i]\n",
      "    # uncomment to view data 1 by 1\n",
      "    # viewer = VtkViewer()\n",
      "    for i,p in points_dict.iteritems():\n",
      "        ac = get_sphere_actor(*p)\n",
      "        ac.GetProperty().SetColor(c)\n",
      "        if i == 3:\n",
      "            #The front sample\n",
      "            ac.GetProperty().SetRepresentationToWireframe()\n",
      "        viewer.add_actor(ac)\n",
      "    #and lets add some lines\n",
      "    lines = [(1,3),(3,2),(2,4),(4,1),(1,2)]\n",
      "    for p1,p2 in lines:\n",
      "        acl = get_line_actor(points_dict[p1],points_dict[p2])\n",
      "        acl.GetProperty().SetColor(c)\n",
      "        viewer.add_actor(acl)\n",
      "    # uncomment to view data 1 by 1\n",
      "    viewer.start()\n",
      "    #del viewer\n",
      "viewer.start()\n",
      "del viewer\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If some sample looks weird, you may use the above code to look at them individually\n",
      "\n",
      "Now lets look at the data from stage_two"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "viewer = VtkViewer()\n",
      "for i,pts in enumerate(stage_two_pairs):\n",
      "    c = colors[i]\n",
      "    for pos,orn in pts:\n",
      "        center = get_sphere_actor(*pos)\n",
      "        center.GetProperty().SetColor(c)\n",
      "        dummy_q = quat.Quaternion([0,0.1,0,0])\n",
      "        dummy_qr = orn * dummy_q * orn.conj()\n",
      "        dummy_v = dummy_qr.x[1:]\n",
      "        ln = get_line_actor(pos,dummy_v+pos)\n",
      "        ln.GetProperty().SetColor(c)\n",
      "        viewer.add_actor(ln)\n",
      "        viewer.add_actor(center)\n",
      "viewer.start()\n",
      "del viewer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If everything looks fine continue to the next section, otherwise data should be fixed."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.2 Find target points in stage_one data\n",
      "\n",
      "The first thing we must do is find the center of the coil, and the hypothetical point directly over it from the data in stage_one. For this we will do some linear algebra.\n",
      "\n",
      "<img src=\"files/tmsCaliVecs.png\">\n",
      "\n",
      "The point pc will represent the center of the coil, and will be the projection of v2 over v1. The hypotetical point ph will be located 0.1 units directly on top of pc. By directly on top, we mean across the perpendicular vector to the plane that contains p1, p2 and p3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coil_centers = list()\n",
      "coil_tops = list()\n",
      "for points_dict in stage_one_dicts:\n",
      "    p1 = points_dict[1]\n",
      "    p2 = points_dict[2]\n",
      "    p3 = points_dict[3]\n",
      "    \n",
      "    v1 = p2 - p1\n",
      "    v2 = p3 - p1\n",
      "    v1_u = v1/np.linalg.norm(v1) # unitary vector\n",
      "    v2_p = np.dot(v2,v1_u)*v1_u # projection of v2 on v1\n",
      "    pc = p1 + v2_p\n",
      "    coil_centers.append(pc)\n",
      "    \n",
      "    vp = np.cross(v1,v2) # perpendicular vector\n",
      "    vp_u = vp/np.linalg.norm(vp) # unitary\n",
      "    ph = pc + 0.1*vp_u\n",
      "    coil_tops.append(ph)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets add this features to the picture we had of the stage_one data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "viewer = VtkViewer()\n",
      "for i,points_dict in enumerate(stage_one_dicts):\n",
      "    c = colors[i]\n",
      "    #uncomment to look at an individual case\n",
      "    #if i!=1:\n",
      "    #    continue\n",
      "    for pi,p in points_dict.iteritems():\n",
      "        ac = get_sphere_actor(*p)\n",
      "        ac.GetProperty().SetColor(c)\n",
      "        if pi == 3:\n",
      "            #The front sample\n",
      "            ac.GetProperty().SetRepresentationToWireframe()\n",
      "        viewer.add_actor(ac)\n",
      "    #and lets add some lines\n",
      "    lines = [(1,3),(3,2),(2,4),(4,1),(1,2)]\n",
      "    for p1,p2 in lines:\n",
      "        acl = get_line_actor(points_dict[p1],points_dict[p2])\n",
      "        acl.GetProperty().SetColor(c)\n",
      "        viewer.add_actor(acl)\n",
      "    #add the centers\n",
      "    pc = coil_centers[i]\n",
      "    cact = get_sphere_actor(*pc)\n",
      "    cact.GetProperty().SetColor(c)\n",
      "    viewer.add_actor(cact)\n",
      "    #add lines towards the top\n",
      "    pt = coil_tops[i]\n",
      "    tl = get_line_actor(pc,pt)\n",
      "    tl.GetProperty().SetColor(c)\n",
      "    viewer.add_actor(tl)\n",
      "    \n",
      "    \n",
      "viewer.start()\n",
      "del viewer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.3 Find coil parameters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Theory: The system deliver the coordinates of a position P and an orientation O. The center of the coil and the hypotethetical point at the top can be found as\n",
      "\n",
      "$$P^c = P + O \\times V^c \\times \\overline{O}$$\n",
      "$$P^t = P + O \\times V^t \\times \\overline{O}$$\n",
      "\n",
      "Where $V^c$ and $V^t$ are unknown vectors. The objective here is to find these vectors. Notice these are the same formulas from the pointer calibration.\n",
      "\n",
      "We already have approximate positions for $P_c$ and $P_t$; and now we must find the vectors that connect the coil solid body point P to these points. The equations are therefore\n",
      "\n",
      "$$P^c = P_{j} + O_{j} \\times V^c \\times \\overline{O_{j}} + e^c_{j} $$\n",
      "$$P^t = P_{j} + O_{j} \\times V^t \\times \\overline{O_{j}} + e^t_{j} $$\n",
      "\n",
      "Where e represents the error in the measurement, the objective is to find the values of $V_c$ and $V_t$ that minimize these errors. We should have several sets of samples, each with its own $P^c$, $P^t$ , but $V^c$, $V^t$ should adjust for all of them. For each case we have then\n",
      "\n",
      "$$P^c_i = P_{i,j} + O_{i,j} \\times V^c \\times \\overline{O_{i,j}} + e^c_i,j $$\n",
      "$$P^t_i = P_{i,j} + O_{i,j} \\times V^t \\times \\overline{O_{i,j}} + e^t_i,j $$\n",
      "\n",
      "Let \n",
      "\n",
      "$${f^c_{v}}(p,o) = \\hat{P^c} = p + o \\times v^c \\times \\overline{o} $$\n",
      "$${f^t_{v}}(p,o) = \\hat{P^t} = p + o \\times v^t \\times \\overline{o} $$\n",
      "\n",
      "If we assing the same weight to all the errors, we can define the total error as\n",
      "Given that we don't care specially about the exact position of P^t, but we care of its position relative to P^c we are going to define the following error terms\n",
      "\n",
      "$$e^c = \\left| P^c - \\hat{P^c}\\right| $$\n",
      "$$e^t = \\left| P^t - P^c - (\\hat{P^t} - \\hat{P^c} )\\right| $$\n",
      "\n",
      "And the full error will be equal to\n",
      "\n",
      "$$e^t = e^c + e^t $$\n",
      "\n",
      "We will estimate both parameters at the same time. Notice it would be possible to assign different weight to both kinds of errors in order to create a trade off between weight of errors in both parameters\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coil_center_error(vc):\n",
      "    tot_error = 0\n",
      "    f = get_point_function(vc)\n",
      "    for ct,(pairs) in izip(coil_centers,stage_two_pairs):\n",
      "        mapped_centers = np.array([f(pj.pos,pj.orn) for pj in pairs])\n",
      "        #L1 norm more robust to outliers than quadratic error\n",
      "        tot_error += sum(abs(np.linalg.norm(p-ct))**2 for p in mapped_centers )\n",
      "    return tot_error\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coil_top_error(vt,vc):\n",
      "    #what matters here is the angle between the two vectors\n",
      "    tot_error = 0\n",
      "    f_t = get_point_function(vt)\n",
      "    f_c = get_point_function(vc)\n",
      "    for top,ctr,(pairs) in izip(coil_tops,coil_centers,stage_two_pairs):\n",
      "        #for each case\n",
      "        mapped_tops = [f_t(pj.pos,pj.orn) for pj in pairs]\n",
      "        mapped_centers = [f_c(pj.pos,pj.orn) for pj in pairs]\n",
      "        #L1 norm more robust to outliers than quadratic error\n",
      "        v1s = [tp - ct for tp,ct in izip(mapped_tops,mapped_centers)]\n",
      "        v2 = top - ctr\n",
      "        #angle_error = lambda v11,v22: np.linalg.norm(np.cross(v11,v22))/(np.linalg.norm(v11)*np.linalg.norm(v22))\n",
      "        angle_error = lambda v11,v22: 1-(np.dot(v11,v22))/(np.linalg.norm(v11)*np.linalg.norm(v22))\n",
      "        errors = [angle_error(v1,v2) for v1 in v1s]\n",
      "        #print v1s\n",
      "        tot_error += (sum(errors))\n",
      "    return tot_error\n",
      "                            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def total_coil_error(vct):\n",
      "    vc = vct[0:3]\n",
      "    vt = vct[3:6]\n",
      "    return coil_center_error(vc)**2+coil_top_error(vt,vc)**2+100*(np.linalg.norm(vt-vc)-0.1)**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vct = np.zeros(6)\n",
      "vct[0:5]=0.1\n",
      "#just a little test\n",
      "print total_coil_error(vct)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "36.4681668302\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test inverse vec function\n",
      "t1 = coil_centers[0]\n",
      "pair1 = stage_two_pairs[0][0]\n",
      "\n",
      "cand = find_inverse_vec(t1,pair1)\n",
      "print t1\n",
      "print pair1\n",
      "print cand\n",
      "\n",
      "#test\n",
      "c_f = get_point_function(cand)\n",
      "print c_f(*pair1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.04258198 -0.22975429 -0.32375246]\n",
        "PointerSample(pos=array([-0.00048305, -0.18431365, -0.32396275]), orn=Quaternion:\n",
        "array([ 0.9247629 ,  0.22133461,  0.27592117,  0.14032865]))\n",
        "[ 0.01737347 -0.04501355  0.03989278]\n",
        "[ 0.04258198 -0.22975429 -0.32375246]\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ctr_guess = np.mean([find_inverse_vec(c,pc[0]) for c,pc in izip(coil_centers,stage_two_pairs)] ,axis=0)\n",
      "print ctr_guess\n",
      "top_guess = np.mean([find_inverse_vec(t,pc[0]) for t,pc in izip(coil_tops,stage_two_pairs)] ,axis=0)\n",
      "print top_guess\n",
      "print top_guess - ctr_guess\n",
      "print np.linalg.norm(top_guess-ctr_guess)\n",
      "guess = np.concatenate((ctr_guess,top_guess))\n",
      "print\n",
      "print coil_center_error(ctr_guess)\n",
      "print coil_top_error(top_guess,ctr_guess)\n",
      "print total_coil_error(guess)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.02090126 -0.04384719  0.04535212]\n",
        "[ 0.0507516   0.03728957 -0.00464037]\n",
        "[ 0.02985033  0.08113676 -0.04999248]\n",
        "0.0998672324907\n",
        "\n",
        "0.000330419054809\n",
        "0.0187557629059\n",
        "0.000353650540086\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = scipy.optimize.minimize(total_coil_error,guess)\n",
      "print res\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   status: 0\n",
        "  success: True\n",
        "     njev: 15\n",
        "     nfev: 120\n",
        " hess_inv: array([[  0.9744822 ,   1.41096394,  -5.2231147 ,   0.96408342,\n",
        "          1.41304842,  -5.22518579],\n",
        "       [  1.41096394,   4.75047451, -15.71355362,   1.41277171,\n",
        "          4.74508422, -15.71959197],\n",
        "       [ -5.2231147 , -15.71355362,  58.64389942,  -5.22353153,\n",
        "        -15.7165968 ,  58.64435001],\n",
        "       [  0.96408342,   1.41277171,  -5.22353153,   0.97441043,\n",
        "          1.41061238,  -5.22302273],\n",
        "       [  1.41304842,   4.74508422, -15.7165968 ,   1.41061238,\n",
        "          4.75034014, -15.71535173],\n",
        "       [ -5.22518579, -15.71959197,  58.64435001,  -5.22302273,\n",
        "        -15.71535173,  58.66246809]])\n",
        "      fun: 0.0003497196014797175\n",
        "        x: array([ 0.02067593, -0.04422118,  0.04636316,  0.05078185,  0.03707663,\n",
        "       -0.00347958])\n",
        "  message: 'Optimization terminated successfully.'\n",
        "      jac: array([ -1.26892701e-08,  -6.12089934e-08,  -3.90573405e-08,\n",
        "         6.84558472e-08,   2.16030458e-07,  -9.02728061e-08])\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets see the results the vct vector, and the final value of the error. Check that the final status is 0, and success is True... otherwise adjustments should be made to the initial values or model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Success: \", res.success\n",
      "print res.fun\n",
      "vc=res.x[0:3]\n",
      "vt=res.x[3:6]\n",
      "#vc = guess[0:3]\n",
      "#vt = guess[3:6]\n",
      "\n",
      "print vc\n",
      "print vt\n",
      "print np.linalg.norm(vt-vc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Success:  True\n",
        "0.00034971960148\n",
        "[ 0.02067593 -0.04422118  0.04636316]\n",
        "[ 0.05078185  0.03707663 -0.00347958]\n",
        "0.099999997626\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.4 Verifying results\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets calculate the mappings from the stage_two samples to centers and tops"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_c = get_point_function(vc)\n",
      "f_t = get_point_function(vt)\n",
      "mapped_centers = [map(lambda p:f_c(p.pos,p.orn),s) for s in stage_two_pairs]\n",
      "mapped_tops = [map(lambda p:f_t(p.pos,p.orn),s) for s in stage_two_pairs]\n",
      "print (zip(mapped_centers,mapped_tops)[0])[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[array([ 0.04884657, -0.22995794, -0.31999569]), array([ 0.04899837, -0.22934862, -0.32108133]), array([ 0.04867709, -0.22961959, -0.32048866]), array([ 0.0480701 , -0.2293999 , -0.32088206])]\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets use vtk to verify the calibration results, we will reuse some of the code from section 2.1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "viewer = VtkViewer()\n",
      "for i,points_dict in enumerate(stage_one_dicts):\n",
      "    c = colors[i]\n",
      "    for pi,p in points_dict.iteritems():\n",
      "        ac = get_sphere_actor(*p)\n",
      "        ac.GetProperty().SetColor(c)\n",
      "        if pi == 3:\n",
      "            #The front sample\n",
      "            ac.GetProperty().SetRepresentationToWireframe()\n",
      "        viewer.add_actor(ac)\n",
      "    #and lets add some lines\n",
      "    lines = [(1,3),(3,2),(2,4),(4,1),(1,2)]\n",
      "    for p1,p2 in lines:\n",
      "        acl = get_line_actor(points_dict[p1],points_dict[p2])\n",
      "        acl.GetProperty().SetColor(c)\n",
      "        viewer.add_actor(acl)\n",
      "    #add the centers\n",
      "    pc = coil_centers[i]\n",
      "    cact = get_sphere_actor(*pc)\n",
      "    cact.GetProperty().SetColor(c)\n",
      "    viewer.add_actor(cact)\n",
      "    #add lines towards the top\n",
      "    pt = coil_tops[i]\n",
      "    tl = get_line_actor(pc,pt)\n",
      "    tl.GetProperty().SetColor(c)\n",
      "    viewer.add_actor(tl)\n",
      "    \n",
      "    \n",
      "#viewer.start()\n",
      "#del viewer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's add the mapped points and tops"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(len(mapped_centers)):\n",
      "    c = colors[i]\n",
      "    samp_ctrs = mapped_centers[i]\n",
      "    samp_tops = mapped_tops[i]\n",
      "    for pc,tp in izip(samp_ctrs,samp_tops):\n",
      "        ac = get_sphere_actor(*pc)\n",
      "        ac.GetProperty().SetColor(c)\n",
      "        ac.GetProperty().SetRepresentationToWireframe()\n",
      "        viewer.add_actor(ac)\n",
      "        la = get_line_actor(pc,tp)\n",
      "        la.GetProperty().SetColor((1,1,1)) # white to distinguish from model line\n",
      "        viewer.add_actor(la)\n",
      "        \n",
      "\n",
      "viewer.start()\n",
      "del viewer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.5 Save Results\n",
      "\n",
      "If everything looks ok, let's copy the results to the file calibration_data.py\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Final V\n",
      "vc=res.x[0:3]\n",
      "vt=res.x[3:]\n",
      "print tuple(vc), \",\"\n",
      "print tuple(vt), \",\"\n",
      "#Final error\n",
      "print res.fun, \"),\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.020675926635637075, -0.044221175627285544, 0.046363164818019435) ,\n",
        "(0.050781845269221811, 0.037076632862961804, -0.0034795831309582508) ,\n",
        "0.00034971960148 ),\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.6 Test saved results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from tms.read_and_transform import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "viewer = VtkViewer()\n",
      "for i,points_dict in enumerate(stage_one_dicts):\n",
      "    c = colors[i]\n",
      "    for pi,p in points_dict.iteritems():\n",
      "        ac = get_sphere_actor(*p)\n",
      "        ac.GetProperty().SetColor(c)\n",
      "        if pi == 3:\n",
      "            #The front sample\n",
      "            ac.GetProperty().SetRepresentationToWireframe()\n",
      "        #viewer.add_actor(ac)\n",
      "    #and lets add some lines\n",
      "    lines = [(1,3),(3,2),(2,4),(4,1),(1,2)]\n",
      "    for p1,p2 in lines:\n",
      "        acl = get_line_actor(points_dict[p1],points_dict[p2])\n",
      "        acl.GetProperty().SetColor(c)\n",
      "        viewer.add_actor(acl)\n",
      "    #add the centers\n",
      "    pc = coil_centers[i]\n",
      "    cact = get_sphere_actor(*pc)\n",
      "    cact.GetProperty().SetColor(c)\n",
      "    viewer.add_actor(cact)\n",
      "    #add lines towards the top\n",
      "    pt = coil_tops[i]\n",
      "    tl = get_line_actor(pc,pt)\n",
      "    tl.GetProperty().SetColor(c)\n",
      "    viewer.add_actor(tl)\n",
      "    \n",
      "coil_function = get_coil_transform_function(stage_two[0][0].date)\n",
      "first_samples = map(lambda x:x[0],stage_two)\n",
      "centers = map(coil_function,first_samples)\n",
      "for p,c in izip(first_samples,centers):\n",
      "    print p\n",
      "    print c\n",
      "    \n",
      "\n",
      "\n",
      "for c,t in centers:\n",
      "    cact = get_sphere_actor(*c)\n",
      "    viewer.add_actor(cact)\n",
      "    lact = get_line_actor(c,t)\n",
      "    viewer.add_actor(lact)\n",
      "    \n",
      "viewer.start()\n",
      "del viewer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'coil_centers' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-90d0095714ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_actor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#add the centers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mpc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoil_centers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mcact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sphere_actor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mcact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetProperty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSetColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'coil_centers' is not defined"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}